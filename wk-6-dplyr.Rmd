---
title: "Data manipulation with dplyr"
author: "group 6: Finn Womack, Lorne Curran, Martin Leandro Uranga Priore, Chenyang Duo, Emerson Webb, Jiarui Xu"
date: "5/10/2019"
output: pdf_document
---

```{r, include=FALSE, message=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE, 
                      fig.show = "hold", out.width="50%")
library(tidyverse)
library(nycflights13)
library(maps)
rm(list = ls())
```

### 5.7.1.2 Which plane (tailnum) has the worst on-time record?

There's no unequivocal definition of worst record here. If it's binary: either at the gate by the scheduled time or not, we can deliver a proportion of on-time:
```{r}
on_time <- 
flights %>%
  filter(!(is.na(arr_delay)), !is.na(tailnum)) %>% 
  group_by(tailnum) %>%
  summarize(ot_rec = sum(arr_delay <= 0)/n(),
            n = n()) %>%
  arrange(ot_rec) %>%
  select(tailnum, ot_rec, n)

head(on_time, n = 3)
```

Those with no on-time flights have company, but a whole lot of tailnums have a piddly count of flights. We can look at the whole spread, then drill down to a meaningful breakpoint:
```{r}
ggplot(on_time, aes(n, ot_rec)) +
  geom_point()

on_time %>% 
  filter(n == n[between(n, 20, 100)]) %>% 
  ggplot(aes(n, ot_rec)) +
    geom_point()
```

It looks like there's some losers among those with 20 or more flights in 2013. We'll choose the worst of those.
```{r}
on_time %>%
  filter(n > 20) %>% 
  head(n = 4)
```

Tailnum N988AT arrived on time for only 20% of its 35 flights.

If on-time record is referring to average number of minutes late:
```{r}
flights %>%
  filter(!(is.na(arr_delay)), !(is.na(tailnum)),
         arr_delay > 0) %>% 
  group_by(tailnum) %>%
  summarize(ot_rec = mean(arr_delay),
            n = n()) %>%
  arrange(desc(ot_rec)) %>%
  select(tailnum, ot_rec, n) %>% 
  head(n = 2)
```

We have a "winner" here (N844MH), but then it only made 1 flight.

### 5.7.1.4 For each destination, compute the total minutes of delay. For each flight, compute the proportion of the total delay for its destination.

This takes the sum of all delays for each destination (including negatives) then for each flight in the dataset finds the ratio of the arrival delay (also including negatives so this can be a negative ratio) to the total delay. Total delay per destination:
```{r}
flights %>%
  filter(!(is.na(arr_delay))) %>% 
  group_by(dest) %>%
  summarise(total_delay = sum(arr_delay)) %>% 
  select(dest, total_delay) %>% 
  arrange(dest)
```

For each flight, its proportion of the total delay for its destination:
```{r}
flights %>% 
  filter(!(is.na(arr_delay))) %>% 
  group_by(dest) %>% 
    mutate(total_delay = sum(arr_delay),
           delay_prop = arr_delay/total_delay) %>% 
  select(month, day, flight, delay_prop, dest, total_delay) %>% 
  arrange(month, day, flight) %>% 
  head()
```

Or we can introduce a minor change by assuming that the delay cannot be negative.
```{r}
flights %>%
  filter(!(is.na(arr_delay)), !(is.na(dest)),
         arr_delay > 0) %>% 
  group_by(dest) %>%
  mutate(
    total_delay = sum(arr_delay),
    delay_prop = arr_delay / total_delay
  ) %>%
  select(month, day, dep_time, flight, delay_prop, dest, total_delay) %>%
  arrange(month, day, flight) %>% 
  head()
```

\pagebreak


### 5.7.1.6 Look at each destination. Can you find flights that are suspiciously fast? (i.e. flights that represent a potential data entry error). Compute the air time a flight relative to the shortest flight to that destination. Which flights were most delayed in the air?

I tried finding outliers by using the 1st quantile - 1.5*IQR rule of thumb and got 90 flights:

```{r}
flights %>%
  group_by(dest) %>%
  mutate(out = quantile(air_time, 0.25, na.rm = TRUE) - 1.5*IQR(air_time, na.rm = TRUE)) %>%
  filter(air_time < out)
```



The ten most delayed in the air flights are the following: (Should we be filtering outliers for this second part?)

```{r}
flights %>%
  group_by(dest) %>%
  mutate(min_air = min(air_time, na.rm=TRUE)) %>%
  mutate(air_delay = air_time - min_air) %>%
  arrange(desc(air_delay)) %>%
  select(dest, year:day, flight, air_time, air_delay)
```

(if so then the code would be altered like so:)

```{r}
flights %>%
  group_by(dest) %>%
  mutate(out = quantile(air_time, 0.25, na.rm = TRUE) - 1.5*IQR(air_time, na.rm = TRUE)) %>%
  filter(air_time >= out) %>%
  group_by(dest) %>%
  mutate(min_air = min(air_time, na.rm=TRUE)) %>%
  mutate(air_delay = air_time - min_air) %>%
  arrange(desc(air_delay)) %>%
  select(dest, year:day, flight, air_time, air_delay)
```

I like Finn approach but I think we must consider grouping by destination and the origin to define what is most delayed. Also using a standarization with the median (more resistant to outliers than the mean) and selecting the most negative standard normal values can be useful:

```{r}
stand_fli <- flights %>%
  filter(!is.na(air_time)) %>%
  group_by(dest, origin) %>%
  mutate(
    median_airtime = median(air_time),
    iqr_airtime = IQR(air_time),
    n = n(),
    standard_airtime = (air_time - median_airtime) / iqr_airtime)
```

```{r}

stand_fli %>%
  arrange(standard_airtime) %>%
  select(
    carrier, flight, origin, dest, month, day, air_time,
    median_airtime, standard_airtime) %>%
  print(width = 120)
```

### 13.4.6. 1 Compute the average delay by destination, then join on the airports data frame so you can show the spatial distribution of delays. (See R4DS for code to help here.)



```{r}
av_delay=flights %>%
  filter(arr_delay > 0 | dep_delay > 0) %>%
  group_by(dest) %>%
  summarise(ave_delay = ((mean(arr_delay, na.rm = TRUE)+mean(dep_delay, na.rm = TRUE))/2))


airports %>%
  right_join(av_delay, by = c('faa'='dest')) %>%
  ggplot(aes(lon, lat, color=ave_delay)) +
    borders("state") +
    geom_point() +
    coord_quickmap()

```
